{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import os\n",
      "from pandas.tools.plotting import scatter_matrix\n",
      "from datetime import date, datetime, timedelta\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.mlab as mlab\n",
      "import matplotlib as mpl\n",
      "%matplotlib inline\n",
      "import seaborn as sns\n",
      "sns.set_style(\"white\")\n",
      "from scipy import stats\n",
      "import statsmodels.api as sm\n",
      "from statsmodels.graphics import tsaplots\n",
      "from sklearn import linear_model\n",
      "from scipy.stats import norm,ttest_ind\n",
      "from statsmodels.graphics.api import qqplot\n",
      "from __future__ import print_function\n",
      "from scipy import stats\n",
      "import copy\n",
      "import numpy as np\n",
      "import os.path\n",
      "from ggplot import *\n",
      "from matplotlib.cm import cool\n",
      "import re\n",
      "import yaml\n",
      "from flexbox import psql\n",
      "from flexbox import psql_server\n",
      "\n",
      "\n",
      "#Brining Libraries for FlexBox Data\n",
      "from sqlalchemy import create_engine\n",
      "from sqlalchemy import MetaData, Column, Table\n",
      "from sqlalchemy import Integer, String, DateTime, Boolean, Float, func\n",
      "from sqlalchemy.orm import Session, sessionmaker\n",
      "from sqlalchemy.ext.declarative import declarative_base\n",
      "\n",
      "#Bringing in Libraries for Grid 20 second Data\n",
      "from niuera_nica import psql_niuera_cndc_hourly as psql_hour\n",
      "from sqlalchemy import cast,Date,text\n",
      "from niuera_nica import psql_niuera_real_time\n",
      "from flexbox import psql_server\n",
      "from niuera_nica import psql_niuera_control"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Read the Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_price_data(source,date_select,resample_choice):\n",
      "    \n",
      "    price_pred_dic = {}\n",
      "    \n",
      "    \n",
      "    ##### 1. Bringing in Price Data\n",
      "    \n",
      "    if source == \"server\":\n",
      "        engine = create_engine('postgresql://niuera_analyzer:analysis@cooljoule.javirosa.com/cndc_hourly_db')\n",
      "        metadata = MetaData(bind=engine)\n",
      "    else:\n",
      "        metadata = psql_hour.get_metadata()\n",
      "        \n",
      "    table_dict = psql_hour.setup_tables(metadata)\n",
      "    column_names = table_dict['posdespacho_spot_table'].columns.keys()\n",
      "    \n",
      "    price_frame = pd.DataFrame(table_dict['posdespacho_spot_table'].select().\\\n",
      "                              where(table_dict['posdespacho_spot_table'].c.datetime>=date_select).\\\n",
      "                              order_by(table_dict['posdespacho_spot_table'].c.datetime.asc()).execute().fetchall(),columns=column_names)\n",
      "    price_frame.index = price_frame['datetime']\n",
      "    price_frame['date'] = price_frame.index.date\n",
      "    price_frame['hour'] = price_frame.index.hour\n",
      "    \n",
      "    \n",
      "    ##### 2. Hourly Post Despacho Data\n",
      "    \n",
      "    # Server Connection\n",
      "    if source == \"server\":\n",
      "        engine = create_engine('postgresql://niuera_analyzer:analysis@cooljoule.javirosa.com/cndc_hourly_db')\n",
      "        metadata = MetaData(bind=engine)\n",
      "    else:\n",
      "        metadata = psql_hour.get_metadata()\n",
      "    \n",
      "    table_dict = psql_hour.setup_tables(metadata)\n",
      "    column_names = table_dict['posdespacho_table'].columns.keys()\n",
      "    \n",
      "    post_frame = pd.DataFrame(table_dict['posdespacho_table'].select().\\\n",
      "                              where(table_dict['posdespacho_table'].c.datetime>=date_select).\\\n",
      "                              order_by(table_dict['posdespacho_table'].c.datetime.asc()).execute().fetchall(),columns=column_names)\n",
      "    post_frame.index = post_frame['datetime']\n",
      "    post_frame['date'] = post_frame.index.date\n",
      "    post_frame['hour'] = post_frame.index.hour\n",
      "\n",
      "\n",
      "    ##### 2. Hourly Prediction Data\n",
      "    \n",
      "    # Server Connection\n",
      "    if source == \"server\":\n",
      "        engine = create_engine('postgresql://niuera_analyzer:analysis@cooljoule.javirosa.com/cndc_hourly_db')\n",
      "        metadata = MetaData(bind=engine)\n",
      "    else:\n",
      "        metadata = psql_hour.get_metadata()\n",
      "    \n",
      "    table_dict = psql_hour.setup_tables(metadata)\n",
      "    column_names = table_dict['predespacho_table'].columns.keys()\n",
      "    \n",
      "    pred_frame = pd.DataFrame(table_dict['predespacho_table'].select().\\\n",
      "                              where(table_dict['predespacho_table'].c.datetime>=date_select).\\\n",
      "                              order_by(table_dict['predespacho_table'].c.datetime.asc()).execute().fetchall(),columns=column_names)\n",
      "    pred_frame.index = pred_frame['datetime']\n",
      "    pred_frame['date'] = pred_frame.index.date\n",
      "    pred_frame['hour'] = pred_frame.index.hour\n",
      "    \n",
      "    pred_frame['gen_wind'] = pred_frame['AMY1'] + pred_frame['AMY2']+ pred_frame['PBP'] + pred_frame['EOL'] + pred_frame['ABR']\n",
      "    pred_frame['load_inter_total'] = pred_frame['LNI-L9040'] + pred_frame['SND-L9090']+ pred_frame['AMY-L9030'] + pred_frame['TCPI-L9150']\n",
      "    pred_frame['net_demand'] = pred_frame['Demanda'] - pred_frame['gen_wind'] + pred_frame['load_inter_total']\n",
      "    \n",
      "    \n",
      "    ##### 3. Real Time 20 Second and 5 Second Data\n",
      "    \n",
      "    # Server Connection\n",
      "    \n",
      "    if source == \"server\":\n",
      "        engine = create_engine('postgresql://niuera_analyzer:analysis@cooljoule.javirosa.com/niuera_real_time_db')\n",
      "        metadata = MetaData(bind=engine)\n",
      "    else: \n",
      "        metadata = psql_niuera_real_time.get_metadata()\n",
      "    \n",
      "    \n",
      "    table_dict = psql_niuera_real_time.setup_tables(metadata)\n",
      "    \n",
      "    # Extracting 20 Second Data Tables\n",
      "    column_names = table_dict['cndc_20sec_table'].columns.keys()\n",
      "    twenty_sec = pd.DataFrame(table_dict['cndc_20sec_table'].select().\\\n",
      "                              where(table_dict['cndc_20sec_table'].c.datetime>=date_select).\\\n",
      "                              order_by(table_dict['cndc_20sec_table'].c.datetime.asc()).execute().fetchall(),columns=column_names)\n",
      "    twenty_sec.index = twenty_sec['datetime']\n",
      "    twenty_sec['date'] = twenty_sec.index.date\n",
      "    twenty_sec['hour'] = twenty_sec.index.hour\n",
      "    \n",
      "    wind_plants = ['gen_EOL','gen_ABR','gen_AMY','gen_PBP']\n",
      "    wind_plant_limits = [45,40,63,40]\n",
      "    \n",
      "    #Dropping Wind Values that Might be Outliers\n",
      "    twenty_sec.loc[twenty_sec['gen_EOL'] > 45*10, 'gen_EOL'] = None\n",
      "    twenty_sec.loc[twenty_sec['gen_ABR'] > 40*10, 'gen_ABR'] = None\n",
      "    twenty_sec.loc[twenty_sec['gen_AMY'] > 63*10, 'gen_AMY'] = None\n",
      "    twenty_sec.loc[twenty_sec['gen_PBP'] > 40*10, 'gen_PBP'] = None\n",
      "    \n",
      "    twenty_sec['gen_wind'] = (twenty_sec['gen_EOL'] + twenty_sec['gen_ABR'] + twenty_sec['gen_AMY'] + twenty_sec['gen_PBP'])/10\n",
      "    \n",
      "    #Dropping Demand Values that Might be Outliers\n",
      "    twenty_sec['load_total'] =  (twenty_sec['load_BZN'] +  twenty_sec['load_CHG'] + twenty_sec['load_acoyapa'] + twenty_sec['load_altamira'] + twenty_sec['load_amerrisque'] + twenty_sec['load_asososca']+ twenty_sec['load_asturias'] + twenty_sec['load_batahola'] + twenty_sec['load_bluefields']+twenty_sec['load_boaco'] +  twenty_sec['load_chinandega'] + twenty_sec['load_corinto'] + twenty_sec['load_corocito'] + twenty_sec['load_diriamba']+twenty_sec['load_el_mojon'] + twenty_sec['load_el_periodista'] + twenty_sec['load_el_tuma']+twenty_sec['load_el_viejo'] + twenty_sec['load_enacal'] + twenty_sec['load_esteli']+ twenty_sec['load_granada']+twenty_sec['load_la_esperanza'] + twenty_sec['load_la_gateada'] + twenty_sec['load_las_banderas']+ twenty_sec['load_leon_1']+twenty_sec['load_leon_2'] + twenty_sec['load_los_brasiles'] + twenty_sec['load_malpaisillo']+ twenty_sec['load_managua']+twenty_sec['load_masatepe'] + twenty_sec['load_matagalpa'] + twenty_sec['load_matiguas_mulukuku_siuna']+ twenty_sec['load_nadaime']+twenty_sec['load_oriental'] + twenty_sec['load_portezuelo'] + twenty_sec['load_punta_huete']+ twenty_sec['load_rivas']+twenty_sec['load_san_benito'] + twenty_sec['load_san_miguelito'] + twenty_sec['load_san_ramon']+ twenty_sec['load_sandino']+twenty_sec['load_santa_clara'] + twenty_sec['load_sebaco'] + twenty_sec['load_ticuantepe_2']+ twenty_sec['load_tipitapa'] +  twenty_sec['load_yalaguina'])/10\n",
      "    twenty_sec.loc[twenty_sec['load_total'] > 850, 'load_total'] = None\n",
      "    \n",
      "    twenty_sec['load_inter_total'] = (twenty_sec['inter_LNI-L9040'] + twenty_sec['inter_SND-L9090'] + twenty_sec['inter_AMY-L9030']+ twenty_sec['inter_TCPI-L9150'])/10\n",
      "    twenty_sec.loc[twenty_sec['load_inter_total'] < -100, 'load_inter_total'] = None\n",
      "    twenty_sec.loc[twenty_sec['load_inter_total'] > 100, 'load_inter_total'] = None\n",
      "    \n",
      "    #Net Demand\n",
      "    twenty_sec['net_demand'] = twenty_sec['load_total'] - twenty_sec['gen_wind'] #+ twenty_sec['load_inter_total'] \n",
      "    \n",
      "    twenty_sec_resample = twenty_sec.resample(resample_choice).mean().interpolate(method='time')\n",
      "    \n",
      "    \n",
      "    # Extracting 5 Second Data Tables\n",
      "    column_names = table_dict['eor_5sec_table'].columns.keys()\n",
      "    five_sec = pd.DataFrame(table_dict['eor_5sec_table'].select().\\\n",
      "                      where(table_dict['eor_5sec_table'].c.datetime>=date_select).\\\n",
      "                      order_by(table_dict['eor_5sec_table'].c.datetime.asc()).execute().fetchall(),columns=column_names)\n",
      "    five_sec.index = five_sec['datetime']\n",
      "    five_sec['date'] = five_sec.index.date\n",
      "    five_sec['hour'] = five_sec.index.hour\n",
      "    \n",
      "    five_sec['demand_5sec'] = five_sec['demand_ni']/10\n",
      "    five_sec['cr_ni_5sec'] = five_sec['cr_ni']/100\n",
      "    five_sec['ni_cr_5sec'] = five_sec['ni_cr']/100\n",
      "    five_sec['ho_ni_5sec'] = five_sec['ho_ni']/100\n",
      "    five_sec['ni_ho_5sec'] = five_sec['ni_ho']/100\n",
      "    \n",
      "    five_sec_resample = five_sec.resample(resample_choice).mean().interpolate(method='time')\n",
      "\n",
      "    price_pred_dic['price_frame']= price_frame\n",
      "    price_pred_dic['post_frame'] = post_frame\n",
      "    price_pred_dic['pred_frame'] = pred_frame\n",
      "    price_pred_dic['twenty_sec'] = twenty_sec_resample\n",
      "    price_pred_dic['five_sec'] = five_sec_resample\n",
      "    \n",
      "    return(price_pred_dic);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_dics = read_price_data(source=\"local\", date_select=datetime(2016,7,1,0,0), resample_choice = \"1T\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Reading and Merging Data\n",
      "\n",
      "\n",
      "price_frame = data_dics['price_frame'][['datetime','real_liq','date','hour']]\n",
      "post_frame = data_dics['post_frame']\n",
      "pred_frame = data_dics['pred_frame']\n",
      "twenty_sec_resample = data_dics['twenty_sec']\n",
      "five_sec_resample = data_dics['five_sec'][['demand_5sec','cr_ni_5sec','ni_cr_5sec','ni_ho_5sec','ho_ni_5sec']]\n",
      "\n",
      "merged_sec = twenty_sec_resample.merge(five_sec_resample, left_index=True, right_index=True, how = 'right')\n",
      "\n",
      "merged_sec['net_demand'] = merged_sec['demand_5sec'] - merged_sec['gen_wind'] \n",
      "\n",
      "##########\n",
      "########## NOTE : CHECK THE DATA WITHOUT INTERPORLATION. BEFORE THE 5TH OF JULY IT SHOULD NOT BE USED FOR TRAINING DATA #########\n",
      "##########\n",
      "\n",
      "merged_sec = merged_sec[np.isfinite(merged_sec['cr_ni_5sec'])]\n",
      "\n",
      "merged_sec['interconnect'] =  merged_sec['cr_ni_5sec'] + merged_sec['ni_cr_5sec'] - merged_sec['ho_ni_5sec'] + merged_sec['ni_ho_5sec']\n",
      "merged_sec['net_demand'] = merged_sec['demand_5sec'] - merged_sec['gen_wind'] - merged_sec['interconnect']  \n",
      "\n",
      "merged_sec['date'] = merged_sec.index.date\n",
      "merged_sec['hour'] = merged_sec.index.hour\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}